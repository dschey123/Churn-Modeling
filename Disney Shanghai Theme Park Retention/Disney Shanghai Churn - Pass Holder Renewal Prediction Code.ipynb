{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing, Exploratory Analysis, and Visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# Machine Learning\n",
    "## Feature Scaling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## Feature Undersampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "## ML Models Diffrent Algorithms\n",
    "import catboost as cat\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from catboost.utils import get_roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "## Comparision of Performance of all Algorithms\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from collections import Counter\n",
    "\n",
    "## Metrics\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
    "\n",
    "# This enables catboost to show the plot of its training process\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing datasets for year-long period\n",
    "fnb = pd.read_csv('AP FnB_20201101_20211031.csv')\n",
    "merch = pd.read_csv('AP Merch_20201101_20211031.csv')\n",
    "visit = pd.read_csv('AP Visitation_20201101_20211031.csv')\n",
    "survey_QG = pd.read_csv('AP survey QG_20201101_20211031.csv')\n",
    "# expire = pd.read_csv('AP Expired_20211101_20220131.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fnb Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating date formatted column\n",
    "fnb['Date'] = fnb['year'].astype(str) + fnb['month'].astype(str)\n",
    "fnb['Date'] = pd.to_datetime(fnb['Date'], format = '%Y%m')\n",
    "fnb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnb.drop(['year','month'], axis=1, inplace=True)\n",
    "fnb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnb_grouped=fnb.groupby([\"source_id\",'Date']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnb_grouped.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnb_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merch.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating date formatted column\n",
    "merch['Date'] = merch['year'].astype(str) + merch['month'].astype(str)\n",
    "merch['Date'] = pd.to_datetime(merch['Date'], format = '%Y%m')\n",
    "merch.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merch.drop(['year','month'], axis=1, inplace=True)\n",
    "merch.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_grouped=merch.groupby([\"source_id\",'Date']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_grouped.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnb_grouped.rename(columns={'ORDER_AMT':'Order_Amt_fnb', 'ORDER_ITEM_CNT':'Order_Item_Cnt_fnb'}, inplace=True)\n",
    "merch_grouped.rename(columns={'ORDER_AMT':'Order_Amt_merch', 'ORDER_ITEM_CNT':'Order_Item_Cnt_merch'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge merch and fnb datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(fnb_grouped, merch_grouped, how=\"left\", left_on=['source_id', 'Date'], \n",
    "                  right_on=['source_id', 'Date']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visit Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit['is_renewal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating date formatted column\n",
    "visit['Date'] = visit['year'].astype(str) + visit['month'].astype(str)\n",
    "visit['Date'] = pd.to_datetime(visit['Date'], format = '%Y%m')\n",
    "visit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create season columns, we define Spring as month 3-5, Summer as 6-8, Autumn as 9-11, Winter as 12-2\n",
    "seasons = {1:'Winter', 2:'Winter', 3:'Spring', 4:'Spring', 5:'Spring', 6:'Summer', 7:'Summer',\n",
    "          8:'Summer', 9:'Autumn', 10:'Autumn', 11:'Autumn', 12:'Winter'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit['Season'] = visit['month'].apply(lambda x: seasons[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#season_dum = pd.get_dummies(visit['Season'])\n",
    "#visit = visit.join(season_dum)\n",
    "#visit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit.drop(['year','month'], axis=1, inplace=True)\n",
    "visit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge merch, fnb and visit Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged = pd.merge(visit, merged, how=\"left\", left_on=['source_id', 'Date'], \n",
    "                  right_on=['source_id', 'Date']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.drop(['Date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate rows and get one row for each source_id\n",
    "temp_fin = final_merged.drop(['Passtype','Age','MerchSpendLevel','Season'],axis=1)\n",
    "temp_fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fin_grouped=temp_fin.groupby([\"source_id\"]).sum()\n",
    "temp_fin_grouped.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total spending and total purchased item counts for each source_id\n",
    "temp_fin_grouped['Total_Order_Amt'] = temp_fin_grouped['Order_Amt_fnb'] + temp_fin_grouped['Order_Amt_merch']\n",
    "temp_fin_grouped['Total_Order_Cnt'] = temp_fin_grouped['Order_Item_Cnt_fnb'] + temp_fin_grouped['Order_Item_Cnt_merch']\n",
    "temp_fin_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fin_grouped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fin_grouped['Total_Order_Amt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get customer profile for further combination\n",
    "cus_profile = final_merged[['source_id','Passtype','Age','MerchSpendLevel','Season']].copy().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_profile['MerchSpendLevel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cus_profile_dict = cus_profile.set_index('source_id').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add cus profile to the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_res=pd.merge(cus_profile, temp_fin_grouped, how=\"left\", left_on=['source_id'], \n",
    "                  right_on=['source_id']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding passtype, merchspendlevel and age columns\n",
    "# For passtype: 0=Crystal, 1=Diamond, 2=Gold, 3=Silver\n",
    "# For MerchSpendLevel: 0 = 0, 1 = <1K, 2 = >100K, 3 = >10K, 4 = >1K, 5 = >3K, 6 = >5K\n",
    "# For Age: 0=Adult, 1=Select\n",
    "# For Season: 0=Autumn, 1=Spring, 2=Summer, 3=Winter\n",
    "fin_res[\"Passtype_encode\"] = fin_res[\"Passtype\"].astype('category').cat.codes\n",
    "fin_res[\"MerchSpendLevel_encode\"] = fin_res[\"MerchSpendLevel\"].astype('category').cat.codes\n",
    "fin_res['Age_encode'] = fin_res[\"Age\"].astype('category').cat.codes\n",
    "fin_res[\"Season_encode\"] = fin_res[\"Season\"].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_res.drop(['Passtype', 'MerchSpendLevel','Age','Season'],axis=1,inplace=True)\n",
    "fin_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_res.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further cleaning\n",
    "fin_res['is_renewal'] = fin_res['is_renewal'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For several source_ids, they visited the resort but didn't purchase anything for some dates. That's the reason for the 0.00 in the above datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique merchandise\n",
    "#merch['item_desc_secondary'].str.strip()\n",
    "#merch['item_desc_secondary'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_res.to_csv(\"Preprocess_NonSurvey.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survey QG Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_colns = ['respid','buytime_current','LastVisit','exp_date','survey_org','famap_org_1','famap_org_2',\n",
    "             'famap_org_3','famap_org_4','famap_org_5','famap_org_6','famap_org_4_other',\n",
    "             'gender_org','kid_org','Kids_org','Kidsage_org_1','Kidsage_org_2','Kidsage_org_3',\n",
    "              'Kidsage_org_4','Kidsage_org_5','Kidsgender_org_1','Kidsgender_org_2',\n",
    "              'Kidsgender_org_3','Kidsgender_org_4','Kidsgender_org_5','Kidsage_5','Kidsgender_5',\n",
    "             'kid5age','kid5gender','aprecord','aptype','aptype_label','nps_prog_mobile_1',\n",
    "             'rrcry','MainlandChinaYN_org','Province_org','City_Dist_org','CountryMarket_org',\n",
    "              'Pudong_org','MainlandChinaYN_Mobile','Province_Mobile','City_Dist_Mobile','CountryMarket_Mobile',\n",
    "              'Pudong_Mobile','SHDLTrans_98_other','famapno_org','CAWI_Date','responseid','hhincome_org','Kids_m',\n",
    "             'famap_1','famap_2','famap_3','famap_5','famap_6','famap_4','Province','City_Dist','CountryMarket',\n",
    "              'Pudong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_QG.drop(drop_colns,axis=1,inplace=True)\n",
    "survey_QG.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check object columns\n",
    "# besides aptype_current, other columns are just for references and will not be used in modeling\n",
    "obj_QG = survey_QG.select_dtypes(include=['object']).copy()\n",
    "obj_QG.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aptype_current\n",
    "temp_lst_QG1 = survey_QG['aptype_current'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For current passtype: 0=Crystal, 1=Diamond, 2=Gold, 3=Silver\n",
    "temp_lst_QG2 = []\n",
    "for ap in temp_lst_QG1:\n",
    "    if ap == '梦幻水晶卡':\n",
    "        temp_lst_QG2.append(0)\n",
    "    elif ap == '无限钻石卡':\n",
    "        temp_lst_QG2.append(1)\n",
    "    elif ap == '奇妙金卡':\n",
    "        temp_lst_QG2.append(2)\n",
    "    else:\n",
    "        temp_lst_QG2.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_QG['aptype_current_encode'] = pd.DataFrame(temp_lst_QG2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe for modeling and drop remaining object columns\n",
    "QG_modeling = survey_QG.drop(obj_QG.columns.to_list(),axis=1).copy()\n",
    "QG_modeling.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns with missing values\n",
    "QG_modeling.columns[QG_modeling.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with missing value\n",
    "QG_modeling.fillna({'Benefit_FB': QG_modeling['Benefit_FB'].mean(),\n",
    "                 'Benefit_Merch': QG_modeling['Benefit_Merch'].mean(),\n",
    "                 'Benefit_CAKE': QG_modeling['Benefit_CAKE'].mean(),\n",
    "                 'Benefit_Stroller': QG_modeling['Benefit_Stroller'].mean(),\n",
    "                 'Benefit_parking': QG_modeling['Benefit_parking'].mean(),\n",
    "                 'roverall_prog': QG_modeling['roverall_prog'].mean(),\n",
    "                 'adstateoe_prem': QG_modeling['adstateoe_prem'].mean(),\n",
    "                 'adstateoe_entry': QG_modeling['adstateoe_entry'].mean(),\n",
    "                 'adstateoe_event': QG_modeling['adstateoe_event'].mean(),\n",
    "                 'ovvalue_ap': QG_modeling['ovvalue_ap'].mean(),\n",
    "                 'nps_prog_1': QG_modeling['nps_prog_1'].mean(),\n",
    "                 'rtintent_AP': QG_modeling['rtintent_AP'].mean(),\n",
    "                 'adstatecry_rdate': QG_modeling['adstatecry_rdate'].mean(),\n",
    "                 'adstatecry_window': QG_modeling['adstatecry_window'].mean(),\n",
    "                 'adstatecry_cancel': QG_modeling['adstatecry_cancel'].mean(),\n",
    "                 'adstatecry_punish': QG_modeling['adstatecry_punish'].mean(),\n",
    "                 'adstatecry_rprocess': QG_modeling['adstatecry_rprocess'].mean(),\n",
    "                 'adstatecry_entry': QG_modeling['adstatecry_entry'].mean(),\n",
    "                 'adstatecry_hc': QG_modeling['adstatecry_hc'].mean(),\n",
    "                 'return_nonv': 6,\n",
    "                 'rcoupon_CAKE': QG_modeling['rcoupon_CAKE'].mean(),\n",
    "                 'rcoupon_FB': QG_modeling['rcoupon_FB'].mean(),\n",
    "                 'rcoupon_Merch': QG_modeling['rcoupon_Merch'].mean(),\n",
    "                 'rcoupon_parking': QG_modeling['rcoupon_parking'].mean(),\n",
    "                 'rcoupon_Stroller': QG_modeling['rcoupon_Stroller'].mean(),\n",
    "                 }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill rest of the missing values wiith 0\n",
    "QG_modeling.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Check if there is any missing value remains in the dataset\n",
    "# QG_modeling.columns[QG_modeling.isna().any()]\n",
    "msno.matrix(QG_modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QG_modeling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_QG.loc[survey_QG['source_id']==256066]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_res.loc[fin_res['source_id']==256066]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since it is a quaterly survey, some AP holders took the survey multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining QG_modeling with fin_res Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final DataFrame used for modeling\n",
    "df=pd.merge(fin_res, QG_modeling, how=\"left\", left_on=['source_id'], \n",
    "                  right_on=['source_id']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interactive Column Creation\n",
    "df['SpendPerVisit']=df['Total_Order_Amt']/df['visit_times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can decide to drop additional columns that may affect output of models\n",
    "drop_colns_df = ['visit_times','Order_Amt_fnb','Order_Item_Cnt_fnb','Order_Amt_merch','Order_Item_Cnt_merch',\n",
    "                 'Total_Order_Amt','Total_Order_Cnt','TotalMerchSpend','aptype_current_encode','ap_stage',\n",
    "                 'TotalFnBSpend','Totalspend','Spendpervisit','commrec_98','Kidsgender_2','commrec_5','commrec_4',\n",
    "                 'kid2age','kid3age','kid3gender','kid4age','adstateoe_entry','Kidsage_4','Kidsage_3','vbarrier_3',\n",
    "                 'vbarrier_5','Kidsgender_3','vbarrier_9','vbarrier_10','vbarrier_98','commrec_1','vbarrier_6',\n",
    "                'Kidsgender_4','kid4gender','renew_to_NY']\n",
    "df.drop(drop_colns_df,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is an imbalance in the classes present in the target variable ('is_renewal')\n",
    "renewal_counts = df[\"is_renewal\"].value_counts()\n",
    "temp_df = pd.DataFrame({\n",
    "    \"Yes\": renewal_counts.index,\n",
    "    \"No\": renewal_counts.values\n",
    "})\n",
    " \n",
    "plt.figure(figsize = (18,8))\n",
    "sns.barplot(x = \"Yes\", y = \"No\", data = temp_df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slightly imbalanced dataset\n",
    "df.is_renewal.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection - Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier detection and information for each column\n",
    "\n",
    "#def find_outliers_IQR(df):\n",
    "    #q1=df.quantile(0.25)\n",
    "\n",
    "    #q3=df.quantile(0.75)\n",
    "\n",
    "    #IQR=q3-q1\n",
    "\n",
    "    #outliers = df[((df<(q1-1.5*IQR)) | (df>(q3+1.5*IQR)))]\n",
    "\n",
    "    #return outliers\n",
    "\n",
    "#for column in df:\n",
    "    # outliers = find_outliers_IQR(df[column])\n",
    "\n",
    "    #print(df[column].name,':',\"number of outliers: \"+ str(len(outliers)))\n",
    "\n",
    "    #print(df[column].name,':',\"max outlier value: \"+ str(outliers.max()))\n",
    "\n",
    "    #print(df[column].name,':',\"min outlier value: \"+ str(outliers.min()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Outliers - feel free to change the percentile threshold (40/60 -> 15/85, etc.)\n",
    "\n",
    "#for column in df:\n",
    "    #Q1 = np.percentile(df[column], 40,\n",
    "                   #interpolation = 'midpoint')\n",
    "    #Q3 = np.percentile(df[column], 60,\n",
    "                   #interpolation = 'midpoint')\n",
    "    #IQR = Q3 - Q1\n",
    " \n",
    "    #print(\"Old Shape: \", df.shape)\n",
    " \n",
    "    # Upper bound\n",
    "    #upper = np.where(df[column] >= (Q3+1.5*IQR))\n",
    "    # Lower bound\n",
    "    #lower = np.where(df[column] <= (Q1-1.5*IQR))\n",
    " \n",
    "    #''' Removing the Outliers '''\n",
    "    #df.drop(upper[0], inplace = True)\n",
    "    #df.drop(lower[0], inplace = True)\n",
    " \n",
    "    #print(\"New Shape: \", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of all features in the final dataframe - want to keep an eye out for values that wouldn't make sense (ie. negatives)\n",
    "df.hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix Expcet For 'source_id' and 'is_renewal - keep track of which features have high/low correlation\n",
    "corr = df.drop(['source_id','is_renewal'],axis=1).corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "# Heatmap\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr,\n",
    "            vmax=.5,\n",
    "            mask=mask,\n",
    "            # annot=True, fmt='.2f',\n",
    "            linewidths=.2, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "print(get_top_abs_correlations(df.drop(['source_id','is_renewal'],axis=1), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Feature Engineering Ideas:\n",
    "1) Additional Interactive Variables if dependence between variables can be captured\n",
    "2) Binning of Renewal Date periods if possible (seperate into Monthly increments)\n",
    "3) Feature Selection (What to drop and what to keep based on correlation to each other and label specifically)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('is_renewal',axis=1)\n",
    "y = df.is_renewal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()\n",
    "# For MerchSpendLevel: 0 = 0, 1 = <1K, 2 = >100K, 3 = >10K, 4 = >1K, 5 = >3K, 6 = >5K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training set inyo two sets to build and validate the model \n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning source_id values for predictions at the end\n",
    "x_test_id=pd.DataFrame(x_test['source_id'])\n",
    "x_test_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.drop(['source_id'],axis=1,inplace=True)\n",
    "x_train.drop(['source_id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balancing classes \n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "x_train, y_train = under_sampler.fit_resample(x_train, y_train)\n",
    "print(f\"Training target statistics: {Counter(y_train)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search to find best hyperparameters for the CatBoost model - can change values in lists below\n",
    "catb_para = {'learning_rate': [0.01, 0.03, 0.05, 0.07, 0.1,0.13,0.15,0.2],\n",
    "        'depth': [4, 6, 8, 10,12,14,16,20],\n",
    "        'iterations':[10, 50, 100, 200, 400,600,800,1000]}\n",
    "\n",
    "catb = GridSearchCV(estimator=CatBoostClassifier(), param_grid=catb_para, cv=5, scoring='accuracy',\n",
    "                      verbose=1,n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "catb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best hyperparameters based on GridSearch\n",
    "print(catb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost_pool = cat.Pool(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature_importance': catb.best_estimator_.feature_importances_, \n",
    "              'feature_names': X.drop(['source_id'],axis=1).columns}).sort_values(by=['feature_importance'], \n",
    "                                                           ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, catb.predict(x_test)))\n",
    "plot_confusion_matrix(catb, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search to find best hyperparameters for the MLP model - can change values in lists below\n",
    "MLP_para = {'solver': ['lbfgs'], 'max_iter': [1000,1300,1500,1800,2000], 'alpha': [1e-3,1e-4,1e-5], \n",
    "            'hidden_layer_sizes':[(4,2),(5,2),(6,3)], 'random_state':[0,1,2]}\n",
    "MLP = GridSearchCV(MLPClassifier(), MLP_para, n_jobs=-1, verbose=1, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "#                      hidden_layer_sizes=(5, 2), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best hyperparameters based on GridSearch\n",
    "print(MLP.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,MLP.predict(x_test)))\n",
    "plot_confusion_matrix(MLP, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search to find best hyperparameters for the Decision Tree model - can change values in lists below\n",
    "tree_para = {'criterion':['gini','entropy'],'max_depth':[4,6,8,10,20,40,70,120,150],'min_samples_split':[4,5,6,7],\n",
    "            'random_state':[0,1,2]}\n",
    "tree = GridSearchCV(DecisionTreeClassifier(), tree_para, n_jobs=-1, verbose=1, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best hyperparameters based on GridSearch\n",
    "print(tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature_importance': tree.best_estimator_.feature_importances_, \n",
    "              'feature_names': X.drop(['source_id'],axis=1).columns}).sort_values(by=['feature_importance'], \n",
    "                                                           ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree = DecisionTreeClassifier(random_state=0, max_depth=6, min_samples_split=15)\n",
    "print(classification_report(y_test, tree.predict(x_test)))\n",
    "plot_confusion_matrix(tree, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best Combo from grid_search: RandomForestClassifier(max_depth=110, max_features=3, min_samples_leaf=3,\n",
    "                       min_samples_split=8, n_estimators=300)\n",
    "- The performance is worse wiith the best combo, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search to find best hyperparameters for the Random Forest model - can change values in lists below\n",
    "forest_para = {'criterion':['gini','entropy'],'max_depth':[110,115,116,117,118,119,120], 'max_features':[1,2,3,4,5],\n",
    "               'n_estimators':[250,300,350]}\n",
    "forest = GridSearchCV(estimator=RandomForestClassifier(), param_grid=forest_para, cv=5, scoring='accuracy',\n",
    "                      verbose=1,n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best hyperparameters based on GridSearch\n",
    "print(forest.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature_importance': forest.best_estimator_.feature_importances_, \n",
    "              'feature_names': X.drop(['source_id'],axis=1).columns}).sort_values(by=['feature_importance'], \n",
    "                                                           ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, forest.predict(x_test)))\n",
    "plot_confusion_matrix(forest, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search to find best hyperparameters for the Gradient Boosting model - can change values in lists below\n",
    "gboost_para = {\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"n_estimators\":[10,100,110,200]\n",
    "    }\n",
    "\n",
    "gboost = GridSearchCV(estimator=GradientBoostingClassifier(), param_grid=gboost_para, cv=5, scoring='accuracy',\n",
    "                      verbose=1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gboost = GradientBoostingClassifier(n_estimators=200, max_depth=2, random_state=0)\n",
    "gboost.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best hyperparameters based on GridSearch\n",
    "print(gboost.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature_importance': gboost.best_estimator_.feature_importances_, \n",
    "              'feature_names': X.drop(['source_id'],axis=1).columns}).sort_values(by=['feature_importance'], \n",
    "                                                           ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, gboost.predict(x_test)))\n",
    "plot_confusion_matrix(gboost, x_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search to find best hyperparameters for the KNN model - can change values in lists below\n",
    "k_range = list(range(1, 31))\n",
    "weights=['distance']\n",
    "knn_para = dict(n_neighbors=k_range, weights=weights)\n",
    "  \n",
    "KNN = GridSearchCV(KNeighborsClassifier(), knn_para, cv=5, scoring='accuracy', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "# fitting the model for grid search\n",
    "KNN.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best hyperparameters based on GridSearch\n",
    "print(KNN.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, KNN.predict(x_test)))\n",
    "plot_confusion_matrix(KNN, x_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble machine learning algorithm to combine results from our other models\n",
    "train_model1=tree.predict(x_test)\n",
    "train_model2=forest.predict(x_test)\n",
    "train_model3=gboost.predict(x_test)\n",
    "train_model4=KNN.predict(x_test)\n",
    "train_model5=catb.predict(x_test)\n",
    "train_model6=MLP.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_train=np.column_stack((train_model1,train_model2,train_model3,train_model4,train_model5,train_model6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model.fit(stacked_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_pred=tree.predict(x_test)\n",
    "model2_pred=forest.predict(x_test)\n",
    "model3_pred=gboost.predict(x_test)\n",
    "model4_pred=KNN.predict(x_test)\n",
    "model5_pred=catb.predict(x_test)\n",
    "model6_pred=MLP.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_pred=np.column_stack((model1_pred,model2_pred,model3_pred,model4_pred,model5_pred,model6_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, meta_model.predict(stacked_pred)))\n",
    "plot_confusion_matrix(meta_model, stacked_pred, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC&ROC - Evaluating our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = tree.predict_proba(x_test)\n",
    "p2 = forest.predict_proba(x_test)\n",
    "p3 = gboost.predict_proba(x_test)\n",
    "p4 = KNN.predict_proba(x_test)\n",
    "p5 = catb.predict_proba(x_test)\n",
    "p6 = MLP.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc scores to evaluate our modeling results -> (65-80% probability of distinguishing a \"Non-Renewer\" from a \"Renewer\")\n",
    "auc_score1 = roc_auc_score(y_test, p1[:,1])\n",
    "auc_score2 = roc_auc_score(y_test, p2[:,1])\n",
    "auc_score3 = roc_auc_score(y_test, p3[:,1])\n",
    "auc_score4 = roc_auc_score(y_test, p4[:,1])\n",
    "auc_score5 = roc_auc_score(y_test, p5[:,1])\n",
    "auc_score6 = roc_auc_score(y_test, p6[:,1])\n",
    "\n",
    "print(auc_score1, auc_score2, auc_score3, auc_score4, auc_score5, auc_score6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for models\n",
    "fpr1, tpr1, thresh1 = roc_curve(y_test, p1[:,1], pos_label=1)\n",
    "fpr2, tpr2, thresh2 = roc_curve(y_test, p2[:,1], pos_label=1)\n",
    "fpr3, tpr3, thresh3 = roc_curve(y_test, p3[:,1], pos_label=1)\n",
    "fpr4, tpr4, thresh4 = roc_curve(y_test, p4[:,1], pos_label=1)\n",
    "fpr5, tpr5, thresh5 = roc_curve(y_test, p5[:,1], pos_label=1)\n",
    "fpr6, tpr6, thresh6 = roc_curve(y_test, p6[:,1], pos_label=1)\n",
    "fpr_final, tpr_final, thresh7 = roc_curve(y_test, meta_model.predict(stacked_pred))\n",
    "roc_auc_final = auc(fpr_final, tpr_final)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr1, tpr1, linestyle='--', label='Decision Tree (area = %0.2f)' % auc_score1)\n",
    "plt.plot(fpr2, tpr2, linestyle='--', label='Random Forest (area = %0.2f)' % auc_score2)\n",
    "plt.plot(fpr3, tpr3, linestyle='--', label='Gradient Boost (area = %0.2f)' % auc_score3)\n",
    "plt.plot(fpr4, tpr4, linestyle='--', label='KNN (area = %0.2f)' % auc_score4)\n",
    "plt.plot(fpr5, tpr5, linestyle='--', label='CatBoost (area = %0.2f)' % auc_score5)\n",
    "plt.plot(fpr6, tpr6, linestyle='--', label='MLP (area = %0.2f)' % auc_score6)\n",
    "plt.plot(fpr_final, tpr_final, linestyle=\"--\", label=\"Stacking (area = %0.2f)\" % roc_auc_final)\n",
    "plt.plot(p_fpr, p_tpr, color='black', lw=2)\n",
    "plt.title('ROC Curves')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPE for models - Another evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / np.maximum(np.ones(len(y_true)), np.abs(y_true))))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE(catb.predict(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE(MLP.predict(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE(KNN.predict(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE(gboost.predict(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE(forest.predict(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE(tree.predict(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPE(meta_model.predict(stacked_pred),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next (Optional) Steps - Making Renewal Predictions for each Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For general purposes, you'd have an unseen, test dataframe to predict on, but for our case, we'll the initial x_test dataset/id features\n",
    "\n",
    "#Want to use model with highest predictive accuracy to test on final results***\n",
    "x_test_id['Renewed?']=catb.predict(x_test)\n",
    "x_test_id.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, you could go on to test different discount rates for each (churning) customer and see what discount threshold is needed to prevent churn. \n",
    "\n",
    "Example:\n",
    "\n",
    "Evaluating the impact of an offer to test retention offering scenarios:\n",
    "\n",
    "acceptance_rate_nonchurn = 1,\n",
    "\n",
    "acceptance_rate_churn = 0.48,\n",
    "\n",
    "threshold = 0.48,\n",
    "\n",
    "base_price = $10,\n",
    "\n",
    "discount_amount = $0.48\n",
    "\n",
    "So what would the churn rate be at a price of $9.52?\n",
    "\n",
    "Can change each of these parameters and see likelihood of churn/not churn\n",
    "\n",
    "**REQUIRES ADDITIONAL CODE/DATA**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
